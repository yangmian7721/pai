#!/bin/bash

# Copyright (c) Microsoft Corporation
# All rights reserved.
#
# MIT License
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
# to permit persons to whom the Software is furnished to do so, subject to the following conditions:
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
# BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


# Bootstrap script for docker container.

exec 17>/pai/log/DockerContainerDebug.log
BASH_XTRACEFD=17

function exit_handler()
{
  printf "%s %s\n" \
    "[DEBUG]" "Docker container exit handler: EXIT signal received in docker container, exiting ..."
  kill 0
}

set -x
PS4="+[\t] "
trap exit_handler EXIT


touch "/alive/docker_$PAI_CONTAINER_ID"
while /bin/true; do
  [ $(( $(date +%s) - $(stat -c %Y /alive/yarn_$PAI_CONTAINER_ID) )) -gt 60 ] \
    && pkill -9 --ns 1
  sleep 20
done &


export PAI_WORK_DIR="$(pwd)"
HDFS_LAUNCHER_PREFIX=$PAI_DEFAULT_FS_URI/Container
export CLASSPATH="$(hadoop classpath --glob)"

task_role_no={{{ idx }}}

printf "%s %s\n%s\n\n" "[INFO]" "ENV" "$(printenv | sort)"

mv /pai/code/* ./


function prepare_ssh()
{
  mkdir /root/.ssh
  sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config
  sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
}

function start_ssh_service()
{
  printf "%s %s\n" \
    "[INFO]" "start ssh service"
  cat /root/.ssh/$APP_ID.pub >> /root/.ssh/authorized_keys
  sed -i 's/Port.*/Port '$PAI_CONTAINER_SSH_PORT'/' /etc/ssh/sshd_config
  echo "sshd:ALL" >> /etc/hosts.allow
  service ssh restart
}

function hdfs_upload_atomically()
{
  printf "%s %s\n%s %s\n%s %s\n" \
    "[INFO]" "upload ssh key to hdfs" \
    "[INFO]" "destination path is ${2}" \
    "[INFO]" "source path is ${1}"
  tempFolder=${2}"_temp"
  if hdfs dfs -test -d $tempFolder ; then
    printf "%s %s\n" \
      "[WARNING]" "$tempFolder already exists, overwriting..."
    hdfs dfs -rm -r $tempFolder
  fi
  hdfs dfs -put ${1} $tempFolder
  hdfs dfs -mv $tempFolder ${2}
}

# Check whether hdfs bianry and ssh exists, if not ignore ssh preparation and start part
# Start sshd in docker container
if which hdfs && service --status-all 2>&1 | grep -q ssh; then
  prepare_ssh
  hdfs_ssh_folder=${HDFS_LAUNCHER_PREFIX}/${PAI_USER_NAME}/${PAI_JOB_NAME}/ssh/${APP_ID}
  printf "%s %s\n%s %s\n%s %s\n" \
    "[INFO]" "hdfs_ssh_folder is ${hdfs_ssh_folder}" \
    "[INFO]" "task_role_no is ${task_role_no}" \
    "[INFO]" "PAI_TASK_INDEX is ${PAI_TASK_INDEX}"
  # Let taskRoleNumber=0 and taskindex=0 execute upload ssh files
  if [ ${task_role_no} -eq 0 ] && [ ${PAI_TASK_INDEX} -eq 0 ]; then
    printf "%s %s %s\n%s\n" \
      "[INFO]" "task_role_no:${task_role_no}" "PAI_TASK_INDEX:${PAI_TASK_INDEX}" \
      "Execute upload key pair ..."
    ssh-keygen -N '' -t rsa -f ~/.ssh/$APP_ID
    hdfs dfs -mkdir -p "${hdfs_ssh_folder}"
    hdfs_upload_atomically "/root/.ssh/" "${hdfs_ssh_folder}/.ssh"
  else
    # Waiting for ssh key-pair ready
    while ! hdfs dfs -test -d ${hdfs_ssh_folder}/.ssh ; do
      echo "[INFO] waitting for ssh key ready"
      sleep 10
    done
    printf "%s %s\n%s %s\n" \
      "[INFO]" "ssh key pair ready ..." \
      "[INFO]" "begin to download ssh key pair from hdfs ..."
    hdfs dfs -get "${hdfs_ssh_folder}/.ssh/" "/root/"
  fi
  chmod 400 ~/.ssh/$APP_ID
  # Generate ssh connect info file in "PAI_CONTAINER_ID-PAI_CURRENT_CONTAINER_IP-PAI_CONTAINER_SSH_PORT" format on hdfs
  hdfs dfs -touchz ${hdfs_ssh_folder}/$PAI_CONTAINER_ID-$PAI_CONTAINER_HOST_IP-$PAI_CONTAINER_SSH_PORT

  # Generate ssh config
  ssh_config_path=${HDFS_LAUNCHER_PREFIX}/${PAI_USER_NAME}/${PAI_JOB_NAME}/ssh/config
  hdfs dfs -mkdir -p ${ssh_config_path}
  hdfs dfs -touchz ${ssh_config_path}/$APP_ID+$PAI_CURRENT_TASK_ROLE_NAME+$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX+$PAI_CONTAINER_HOST_IP+$PAI_CONTAINER_SSH_PORT
  while [ `hdfs dfs -ls $ssh_config_path | grep "/$PAI_JOB_NAME/ssh/config/$APP_ID+" | wc -l` -lt  $PAI_JOB_TASK_COUNT ]; do
    printf "%s %s\n" "[INFO]" "Waiting for ssh service in other containers ..."
    sleep 10
  done
  NodeList=($(hdfs dfs -ls ${ssh_config_path} \
    | grep "/$PAI_JOB_NAME/ssh/config/$APP_ID+" \
    | grep -oE "[^/]+$" \
    | sed -e "s/^$APP_ID+//g" \
    | sort -n))
  if [ "${#NodeList[@]}" -ne $PAI_JOB_TASK_COUNT ]; then
    printf "%s %s\n%s\n%s\n\n" \
      "[ERROR]" "NodeList" \
      "${NodeList[@]}" \
      "ssh services in ${#NodeList[@]} containers are available, not equal to $PAI_JOB_TASK_COUNT, exit ..."
    exit 2
  fi
  for line in "${NodeList[@]}"; do
    node=(${line//+/ });
    printf "%s\n  %s\n  %s\n  %s\n  %s\n  %s\n  %s\n" \
      "Host ${node[0]}-${node[1]}" \
      "HostName ${node[2]}" \
      "Port ${node[3]}" \
      "User root" \
      "StrictHostKeyChecking no" \
      "UserKnownHostsFile /dev/null" \
      "IdentityFile /root/.ssh/$APP_ID" >> /root/.ssh/config
  done

  # Start ssh service
  start_ssh_service
fi

# Write env to system-wide environment
env | grep -E "^PAI|PATH|PREFIX|JAVA|HADOOP|NVIDIA|CUDA" > /etc/environment

printf "%s %s\n\n" "[INFO]" "USER COMMAND START"
{{{ taskData.command }}} || exit $?
printf "\n%s %s\n\n" "[INFO]" "USER COMMAND END"

exit 0
